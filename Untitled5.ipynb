{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sks9699/Api/blob/master/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hPn6dywFzFV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8fc5d3-4fea-4d6c-ce55-52c61a5b335c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘~p’: File exists\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ~p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKWQwcAjzRxS",
        "outputId": "0cd00488-6604-42c5-cae6-09934e2b717d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading leaf-class.zip to /content\n",
            "100% 6.55G/6.56G [01:48<00:00, 58.5MB/s]\n",
            "100% 6.56G/6.56G [01:48<00:00, 64.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d sks9699/leaf-class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Nsa50PugzTP1"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/leaf-class.zip','r')\n",
        "zip_ref.extractall('/content/dataset')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ETb6l5pgzvIq"
      },
      "outputs": [],
      "source": [
        "# TRAIN_DIR = \"./DATABASE\"\n",
        "ORG_DIR = \"/content/dataset/dataset/train\"\n",
        "CLASS = ['Alstonia Scholaris',\n",
        "         'Arjun',\n",
        "         'Bael',\n",
        "         'Basil',\n",
        "         'Chinar',\n",
        "         'Gauva',\n",
        "         'Jamun',\n",
        "         'Jatropha',\n",
        "         'Lemon',\n",
        "         'Mango',\n",
        "         'Pomegranate',\n",
        "         'Pongamia Pinnata']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "VXiNwqv11Ji2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from keras.applications.xception  import preprocess_input\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRC92e6P1gsF",
        "outputId": "6f84bc34-836e-4c2b-df5e-5e0abb44b3ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 127, 127, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 62, 62, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 60, 60, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 30, 30, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 115200)            0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               58982912  \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 12)                3084      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59210572 (225.87 MB)\n",
            "Trainable params: 59210572 (225.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define your custom CNN architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(12, activation='softmax'))  # 12 classes for leaf species\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjMyBcZJ1s1v",
        "outputId": "6209c293-5402-4958-8905-077f8980b444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3146 images belonging to 12 classes.\n",
            "Found 894 images belonging to 12 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(featurewise_center=True,\n",
        "                                   rotation_range=0.4,\n",
        "                                   width_shift_range=0.3,\n",
        "                                   horizontal_flip=True,\n",
        "                                   preprocessing_function=preprocess_input,\n",
        "                                   zoom_range=0.4,\n",
        "                                   shear_range=0.4)\n",
        "train_data = train_datagen.flow_from_directory(directory='/content/dataset/dataset/train',\n",
        "                                               target_size=(256, 256),\n",
        "                                               batch_size=36)\n",
        "\n",
        "# Load and preprocess the validation data\n",
        "val_datagen = ImageDataGenerator(featurewise_center=True,\n",
        "                                 preprocessing_function=preprocess_input\n",
        "                                 )\n",
        "val_data = val_datagen.flow_from_directory(directory='/content/dataset/dataset/val',\n",
        "                                           target_size=(256, 256),\n",
        "                                           batch_size=36)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiMlCBix11jc",
        "outputId": "cf5fdf1b-d592-468e-e16b-267fb6e1f441"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Alstonia Scholaris (P2)',\n",
              " 1: 'Arjun (P1)',\n",
              " 2: 'Bael (P4)',\n",
              " 3: 'Basil (P8)',\n",
              " 4: 'Chinar (P11)',\n",
              " 5: 'Gauva (P3)',\n",
              " 6: 'Jamun (P5)',\n",
              " 7: 'Jatropha (P6)',\n",
              " 8: 'Lemon (P10)',\n",
              " 9: 'Mango (P0)',\n",
              " 10: 'Pomegranate (P9)',\n",
              " 11: 'Pongamia Pinnata (P7)'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "train_data.class_indices\n",
        "\n",
        "swapped_dict = {v: k for k, v in train_data.class_indices.items()}\n",
        "swapped_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "yQU_nwgS13wR"
      },
      "outputs": [],
      "source": [
        "t_img,label = train_data.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om9iG8XC15b0",
        "outputId": "3105d8e0-ca13-4408-c587-08e9279ee563"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "t_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xlf0oPkC167W"
      },
      "outputs": [],
      "source": [
        "def plotImage(img_arr,label):\n",
        "  for idx,img in enumerate (img_arr):\n",
        "      if idx<=10:\n",
        "        plt.figure(figsize=(5,5))\n",
        "        plt.imshow(img)\n",
        "        plt.title(img.shape)\n",
        "        plt.axis=False\n",
        "        plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "aQkrA2Oe1-3l"
      },
      "outputs": [],
      "source": [
        "# plotImage(t_img,label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ARKYyJki2AoO"
      },
      "outputs": [],
      "source": [
        "mc = ModelCheckpoint(filepath=\"./best_model.h5\",\n",
        "                     monitor='accuracy',\n",
        "                     verbose=1,\n",
        "                     save_best_only=True)\n",
        "es = EarlyStopping(monitor='accuracy',\n",
        "                   min_delta=0.01,\n",
        "                   patience=5,\n",
        "                   verbose=1)\n",
        "cb = [mc, es]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "his = model.fit_generator(train_data,\n",
        "                          steps_per_epoch=16,\n",
        "                          epochs=25,\n",
        "                          validation_data=val_data,\n",
        "                          validation_steps=16,\n",
        "                          callbacks=cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ86PJTiARxC",
        "outputId": "16c5705f-367c-420c-cd32-21718b1473c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-fcd39093ba96>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  his = model.fit_generator(train_data,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.0899 - accuracy: 0.1337 \n",
            "Epoch 1: accuracy improved from -inf to 0.13368, saving model to ./best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/16 [==============================] - 328s 21s/step - loss: 3.0899 - accuracy: 0.1337 - val_loss: 2.2597 - val_accuracy: 0.1997\n",
            "Epoch 2/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.2322 - accuracy: 0.2066 \n",
            "Epoch 2: accuracy improved from 0.13368 to 0.20660, saving model to ./best_model.h5\n",
            "16/16 [==============================] - 323s 20s/step - loss: 2.2322 - accuracy: 0.2066 - val_loss: 2.0195 - val_accuracy: 0.3090\n",
            "Epoch 3/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.1754 - accuracy: 0.2448 \n",
            "Epoch 3: accuracy improved from 0.20660 to 0.24479, saving model to ./best_model.h5\n",
            "16/16 [==============================] - 303s 19s/step - loss: 2.1754 - accuracy: 0.2448 - val_loss: 2.0035 - val_accuracy: 0.3264\n",
            "Epoch 4/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0955 - accuracy: 0.2812\n",
            "Epoch 4: accuracy improved from 0.24479 to 0.28125, saving model to ./best_model.h5\n",
            "16/16 [==============================] - 313s 20s/step - loss: 2.0955 - accuracy: 0.2812 - val_loss: 1.8959 - val_accuracy: 0.3281\n",
            "Epoch 5/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.0707 - accuracy: 0.3069 \n",
            "Epoch 5: accuracy improved from 0.28125 to 0.30686, saving model to ./best_model.h5\n",
            "16/16 [==============================] - 288s 18s/step - loss: 2.0707 - accuracy: 0.3069 - val_loss: 1.8689 - val_accuracy: 0.3420\n",
            "Epoch 6/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9906 - accuracy: 0.3394\n",
            "Epoch 6: accuracy improved from 0.30686 to 0.33935, saving model to ./best_model.h5\n",
            "16/16 [==============================] - 316s 20s/step - loss: 1.9906 - accuracy: 0.3394 - val_loss: 1.7497 - val_accuracy: 0.3576\n",
            "Epoch 7/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8920 - accuracy: 0.3574\n",
            "Epoch 7: accuracy improved from 0.33935 to 0.35740, saving model to ./best_model.h5\n",
            "16/16 [==============================] - 309s 20s/step - loss: 1.8920 - accuracy: 0.3574 - val_loss: 1.9040 - val_accuracy: 0.3333\n",
            "Epoch 8/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.9693 - accuracy: 0.3194\n",
            "Epoch 8: accuracy did not improve from 0.35740\n",
            "16/16 [==============================] - 306s 19s/step - loss: 1.9693 - accuracy: 0.3194 - val_loss: 1.6504 - val_accuracy: 0.4358\n",
            "Epoch 9/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8379 - accuracy: 0.3574\n",
            "Epoch 9: accuracy did not improve from 0.35740\n",
            "16/16 [==============================] - 308s 20s/step - loss: 1.8379 - accuracy: 0.3574 - val_loss: 1.6799 - val_accuracy: 0.4149\n",
            "Epoch 10/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.8765 - accuracy: 0.3213\n",
            "Epoch 10: accuracy did not improve from 0.35740\n",
            "16/16 [==============================] - 306s 19s/step - loss: 1.8765 - accuracy: 0.3213 - val_loss: 1.7358 - val_accuracy: 0.4097\n",
            "Epoch 11/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7737 - accuracy: 0.3542 \n",
            "Epoch 11: accuracy did not improve from 0.35740\n",
            "16/16 [==============================] - 280s 18s/step - loss: 1.7737 - accuracy: 0.3542 - val_loss: 1.4745 - val_accuracy: 0.4635\n",
            "Epoch 12/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7543 - accuracy: 0.3837\n",
            "Epoch 12: accuracy improved from 0.35740 to 0.38368, saving model to ./best_model.h5\n",
            "16/16 [==============================] - 318s 20s/step - loss: 1.7543 - accuracy: 0.3837 - val_loss: 1.5987 - val_accuracy: 0.4306\n",
            "Epoch 13/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7399 - accuracy: 0.3899 \n",
            "Epoch 13: accuracy improved from 0.38368 to 0.38989, saving model to ./best_model.h5\n",
            "16/16 [==============================] - 283s 18s/step - loss: 1.7399 - accuracy: 0.3899 - val_loss: 1.5947 - val_accuracy: 0.3941\n",
            "Epoch 14/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7878 - accuracy: 0.3854 \n",
            "Epoch 14: accuracy did not improve from 0.38989\n",
            "16/16 [==============================] - 316s 20s/step - loss: 1.7878 - accuracy: 0.3854 - val_loss: 1.4839 - val_accuracy: 0.4861\n",
            "Epoch 15/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.7149 - accuracy: 0.4010 \n",
            "Epoch 15: accuracy improved from 0.38989 to 0.40104, saving model to ./best_model.h5\n",
            "16/16 [==============================] - 289s 18s/step - loss: 1.7149 - accuracy: 0.4010 - val_loss: 1.4344 - val_accuracy: 0.4705\n",
            "Epoch 16/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5854 - accuracy: 0.4184 \n",
            "Epoch 16: accuracy improved from 0.40104 to 0.41840, saving model to ./best_model.h5\n",
            "16/16 [==============================] - 313s 20s/step - loss: 1.5854 - accuracy: 0.4184 - val_loss: 1.2717 - val_accuracy: 0.5781\n",
            "Epoch 17/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5509 - accuracy: 0.4323 \n",
            "Epoch 17: accuracy improved from 0.41840 to 0.43229, saving model to ./best_model.h5\n",
            "16/16 [==============================] - 335s 21s/step - loss: 1.5509 - accuracy: 0.4323 - val_loss: 1.4586 - val_accuracy: 0.4965\n",
            "Epoch 18/25\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.5740 - accuracy: 0.4404"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Wax99DV2ESr"
      },
      "outputs": [],
      "source": [
        "h = his.history\n",
        "h.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h['loss'], 'go--', label='Loss')\n",
        "plt.plot(h['accuracy'], 'go--', color='blue', label='Accuracy')\n",
        "plt.title(\"Loss and Accuracy Over Time\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uC66Kx9IXOJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h['val_loss'], 'go--', label='val_Loss')\n",
        "plt.plot(h['val_accuracy'], 'go--', color='blue', label='val_Accuracy')\n",
        "plt.title(\" val_Loss and val_Accuracy Over Time\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JEgsOu3z5ltz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"/content/best_model.h5\")"
      ],
      "metadata": {
        "id": "npTAF_rx5nVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/dataset/dataset/train/Mango (P0)/0001_0008.JPG\"\n",
        "img = load_img(path,target_size = (256,256))\n",
        "i = img_to_array(img)\n",
        "im = preprocess_input(i)\n",
        "img = np.expand_dims(im,axis=0)\n",
        "pred =np.argmax( model.predict(img))\n",
        "print(\"The Image Belong to: \",swapped_dict[pred])"
      ],
      "metadata": {
        "id": "t4gPROEAWDvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/lemon.jpg\"\n",
        "img = load_img(path,target_size = (256,256))\n",
        "i = img_to_array(img)\n",
        "im = preprocess_input(i)\n",
        "img = np.expand_dims(im,axis=0)\n",
        "pred =np.argmax( model.predict(img))\n",
        "print(\"The Image Belong to: \",swapped_dict[pred])"
      ],
      "metadata": {
        "id": "HLwsha2k85OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSizvfqt9A4-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP7ARhvq3DDpFVq+/JX1qgb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}